{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "586f23a1-a8fd-4263-b2e4-dc2f9145dc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32fe8af1-c7d3-42eb-a8e4-f2f9b85b8df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\murmu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\murmu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c10ae07-72f5-44b7-9f58-29f94c0dbd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            text         category\n",
      "0                    I can't login to my account    Account Issue\n",
      "1            My internet connection is very slow    Network Issue\n",
      "2               Please help me reset my password    Account Issue\n",
      "3              I was overcharged on my last bill    Billing Issue\n",
      "4          The app keeps crashing when I open it  Technical Issue\n",
      "5  My payment failed but the amount was deducted    Billing Issue\n",
      "6        Unable to send messages through the app  Technical Issue\n",
      "7           Payment failed while purchasing plan    Billing Issue\n",
      "8                    Charged twice for one order    Billing Issue\n",
      "9            Money deducted but order not placed    Billing Issue\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV\n",
    "df = pd.read_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/tickets.csv\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a4536df-2347-4021-bbcb-8df6f95f5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "881aed45-4b5f-4d59-ac3b-5e5a6bc803a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by', 'to', 'too', 'from', 'further', \"we're\", 'isn', 'its', 'no', \"they'd\", 'all', 'his', 've', 'i', 'between', 'once', \"she'll\", \"they'll\", 'after', 'he', 'out', 'haven', \"couldn't\", 'few', \"they're\", \"wouldn't\", 'again', 'mustn', 'd', 'had', 'here', 'until', \"won't\", 'not', 'there', 'only', 'these', 'them', 'during', 'this', 'below', 'while', 'off', \"you're\", 'was', \"that'll\", \"you'll\", 'itself', 'who', 'of', 'wasn', \"you'd\", \"you've\", 'will', 'having', 'most', \"needn't\", 'when', \"i've\", 'some', 'll', 'now', 'then', 'being', 'very', 'do', 'their', 'needn', 'won', 'herself', 'our', \"she'd\", \"should've\", \"they've\", 'why', 'it', 'which', \"hasn't\", 'in', 'themselves', 'your', \"i'd\", 'yourself', \"it's\", 'were', 'if', 'yours', 'own', 'such', 'himself', 'we', 'against', 'for', 'hers', \"don't\", 'wouldn', 'under', \"weren't\", 'than', 'can', 'didn', \"we'd\", 'should', 'ourselves', 'hasn', 'because', \"didn't\", 'have', 'my', 'and', 'at', \"shouldn't\", 'yourselves', 'shouldn', \"he's\", 'y', \"mustn't\", 'just', 'a', \"she's\", \"hadn't\", \"i'll\", 'where', 'myself', 'couldn', 'same', 'don', 'both', \"he'll\", 'over', 'the', 'aren', 'doesn', 's', 'how', 'above', 'those', 'is', 'o', \"isn't\", 'with', 'she', 'nor', 'that', 'any', 'through', 'weren', 'me', \"aren't\", 'other', 'so', 'whom', 'ours', \"haven't\", 're', \"we'll\", 'did', 'm', 'but', 'as', \"it'd\", \"mightn't\", 'does', 'down', \"we've\", 'up', 'her', \"i'm\", 'shan', 'each', 'doing', 'him', 'am', 'into', \"he'd\", 'about', 'has', 'more', 'ain', 'an', \"doesn't\", 'mightn', 't', 'theirs', 'before', 'or', \"wasn't\", 'they', 'what', 'hadn', \"it'll\", 'ma', 'be', \"shan't\", 'you', 'been', 'on', 'are'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ed4ac56-319a-4998-bf1a-b478175ba3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "785022d3-9bbf-49f3-88ec-e3342f4d1d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            text  \\\n",
      "0                    I can't login to my account   \n",
      "1            My internet connection is very slow   \n",
      "2               Please help me reset my password   \n",
      "3              I was overcharged on my last bill   \n",
      "4          The app keeps crashing when I open it   \n",
      "5  My payment failed but the amount was deducted   \n",
      "6        Unable to send messages through the app   \n",
      "7           Payment failed while purchasing plan   \n",
      "8                    Charged twice for one order   \n",
      "9            Money deducted but order not placed   \n",
      "\n",
      "                       clean_text  \n",
      "0              cant login account  \n",
      "1        internet connection slow  \n",
      "2      please help reset password  \n",
      "3           overcharged last bill  \n",
      "4         app keeps crashing open  \n",
      "5  payment failed amount deducted  \n",
      "6        unable send messages app  \n",
      "7  payment failed purchasing plan  \n",
      "8         charged twice one order  \n",
      "9     money deducted order placed  \n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "print(df[['text', 'clean_text']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae9cb339-d39e-42eb-9cc0-6016267c2027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: text          0\n",
      "category      0\n",
      "clean_text    0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\", df.isnull().sum())\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68274b19-905d-4d42-a973-525981b6e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/cleaned_tickets.csv\", index=False)\n",
    "print(\"✅ Cleaned dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "854899b3-ef3d-4302-9500-5987ebd75c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Account Issue       5\n",
      "Billing Issue       5\n",
      " Account Issue      5\n",
      "Technical Issue     5\n",
      "Network Issue       4\n",
      " Technical Issue    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/tickets.csv\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2881b292-b7c7-48cb-aa1c-984240ff346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.8\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Account Issue       0.50      1.00      0.67         1\n",
      "  Account Issue       1.00      0.50      0.67         2\n",
      "  Billing Issue       1.00      1.00      1.00         1\n",
      "Technical Issue       1.00      1.00      1.00         1\n",
      "\n",
      "       accuracy                           0.80         5\n",
      "      macro avg       0.88      0.88      0.83         5\n",
      "   weighted avg       0.90      0.80      0.80         5\n",
      "\n",
      "\n",
      "✅ Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# 1️⃣ Load dataset\n",
    "df = pd.read_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/tickets.csv\")\n",
    "\n",
    "# Optional cleaning\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 2️⃣ Split data\n",
    "X = df[\"text\"]        # change column name if needed (e.g., 'text' or 'complaint')\n",
    "y = df[\"category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3️⃣ Vectorize text\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# 4️⃣ Train balanced model\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5️⃣ Evaluate model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 6️⃣ Save model & vectorizer\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "with open(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/model/ticket_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/model/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"\\n✅ Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a565958-f96e-4470-acaf-d7d99fd946bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    text         category\n",
      "0            I can't login to my account    Account Issue\n",
      "1    My internet connection is very slow    Network Issue\n",
      "2       Please help me reset my password    Account Issue\n",
      "3      I was overcharged on my last bill    Billing Issue\n",
      "4  The app keeps crashing when I open it  Technical Issue\n",
      "                                text          category\n",
      "20        Password reset not working     Account Issue\n",
      "21       Forgot my login credentials     Account Issue\n",
      "22             My account got locked     Account Issue\n",
      "23  I can’t sign in even after reset     Account Issue\n",
      "24   computer can't working properly   Technical Issue\n",
      "\n",
      "Category distribution:\n",
      " category\n",
      "Account Issue       5\n",
      "Billing Issue       5\n",
      " Account Issue      5\n",
      "Technical Issue     5\n",
      "Network Issue       4\n",
      " Technical Issue    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/tickets.csv\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(\"\\nCategory distribution:\\n\", df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93158217-8536-4dbf-a138-41f7b2840d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64619fa0-77bc-4407-ada4-0bd45aac6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "✅ Model and vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle, os\n",
    "\n",
    "df = pd.read_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/tickets.csv\")\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "with open(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/model/ticket_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/model/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"✅ Model and vectorizer saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef29d94d-3b10-49b6-822b-b34bc2580078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle, os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/data/tickets.csv\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ✅ Correct column names\n",
    "X = df[\"text\"]\n",
    "y = df[\"category\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6798be8-23e4-4d26-a289-71918932203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40d890c0-d286-4be6-88ac-c6c2c3da2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.8\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Account Issue       0.50      1.00      0.67         1\n",
      "  Account Issue       1.00      0.50      0.67         2\n",
      "  Billing Issue       1.00      1.00      1.00         1\n",
      "Technical Issue       1.00      1.00      1.00         1\n",
      "\n",
      "       accuracy                           0.80         5\n",
      "      macro avg       0.88      0.88      0.83         5\n",
      "   weighted avg       0.90      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f6b9b03-622f-443e-8d82-e116bf1709af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model updated successfully!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"model\", exist_ok=True)\n",
    "with open(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/model/ticket_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"D:/AI_Ticket_Classifier/AI_Ticket_Classifier/model/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"\\n✅ Model updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac012a-4c85-4ea5-8b60-5da73e942c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
